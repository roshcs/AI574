{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¤– Multi-Domain Intelligent Assistant\n",
        "## Supervisor Agent Architecture with Corrective RAG\n",
        "\n",
        "**AI 574: Natural Language Processing â€” Spring 2026**\n",
        "\n",
        "This notebook demonstrates the complete system:\n",
        "1. **Foundation** â€” Load LLM (Gemma 2 9B) and embedding model\n",
        "2. **Ingestion** â€” Index documents across 3 domains\n",
        "3. **CRAG Pipeline** â€” Self-correcting retrieval-augmented generation\n",
        "4. **Agents** â€” Domain-specialized industrial, recipe, and scientific agents\n",
        "5. **Supervisor** â€” Intent classification and routing\n",
        "6. **Evaluation** â€” Routing accuracy, retrieval quality, LLM-judge"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Setup & Installation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q langchain langchain-core langgraph \\\n",
        "    keras keras-hub jax[cuda12] \\\n",
        "    sentence-transformers chromadb \\\n",
        "    PyPDF2 arxiv pydantic"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone or upload project files\n",
        "# Option A: Upload the project/ folder to Colab\n",
        "# Option B: Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '/content/project')  # Adjust path as needed\n",
        "\n",
        "# Set JAX backend for Keras\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'jax'\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Foundation Layer â€” Load Models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from config.settings import CONFIG, LLMConfig\n",
        "from foundation.llm_wrapper import KerasHubChatModel\n",
        "from foundation.embedding_service import EmbeddingService\n",
        "from foundation.vector_store import VectorStoreService\n",
        "\n",
        "# Print configuration\n",
        "print(f\"LLM: {CONFIG.llm.preset}\")\n",
        "print(f\"Embeddings: {CONFIG.embedding.model_name}\")\n",
        "print(f\"Domains: {CONFIG.supervisor.domains}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the LLM (this takes ~2-3 minutes on A100)\n",
        "print(\"Loading LLM...\")\n",
        "llm = KerasHubChatModel(config=CONFIG.llm)\n",
        "print(\"âœ… LLM loaded\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embedding model\n",
        "print(\"Loading embedding model...\")\n",
        "embedder = EmbeddingService(config=CONFIG.embedding)\n",
        "print(\"âœ… Embedding model loaded\")\n",
        "\n",
        "# Quick test\n",
        "test_vec = embedder.embed_query(\"PLC fault code\")\n",
        "print(f\"Embedding dimension: {len(test_vec)}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize vector store\n",
        "vector_store = VectorStoreService(embedding_service=embedder)\n",
        "print(\"âœ… Vector store initialized\")\n",
        "print(vector_store.get_all_stats())"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Ingestion â€” Index Domain Knowledge"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ingestion.index_builder import IndexBuilder\n",
        "\n",
        "index_builder = IndexBuilder(vector_store=vector_store)\n",
        "\n",
        "# â”€â”€ Industrial Domain â”€â”€\n",
        "# Option A: Load from PDF manuals directory\n",
        "# index_builder.index_industrial_docs('./data/manuals/')\n",
        "\n",
        "# Option B: Index sample texts for demo\n",
        "sample_industrial = [\n",
        "    \"\"\"Fault Code F0003 - Siemens S7-1200 PLC: Motor Overtemperature.\n",
        "    Cause: Motor temperature has exceeded the configured warning threshold.\n",
        "    Troubleshooting Steps:\n",
        "    1. Check motor cooling fan operation\n",
        "    2. Verify ambient temperature is within specifications\n",
        "    3. Check for mechanical binding or excessive load\n",
        "    4. Inspect motor winding resistance for signs of degradation\n",
        "    5. Review VFD output current vs motor nameplate rating\n",
        "    Resolution: Reduce load or improve cooling. Reset fault after temperature drops.\"\"\",\n",
        "\n",
        "    \"\"\"PROFINET Configuration Guide - Siemens S7-1200 to S7-1500 Communication.\n",
        "    Prerequisites: Both PLCs must be on the same subnet.\n",
        "    Step 1: In TIA Portal, open the network view\n",
        "    Step 2: Assign IP addresses (e.g., 192.168.0.1 and 192.168.0.2)\n",
        "    Step 3: Create a PROFINET IO system connection\n",
        "    Step 4: Configure I/O data exchange modules\n",
        "    Step 5: Download configurations to both controllers\n",
        "    Step 6: Verify communication using diagnostic buffer\"\"\",\n",
        "\n",
        "    \"\"\"Preventive Maintenance Schedule - Allen-Bradley PowerFlex 525 VFD.\n",
        "    Monthly: Inspect cooling fans, check for dust accumulation\n",
        "    Quarterly: Verify DC bus voltage, check capacitor health indicators\n",
        "    Semi-annually: Tighten all power connections, inspect for signs of overheating\n",
        "    Annually: Full parameter backup, firmware version check, thermal imaging scan\n",
        "    MTBF: Approximately 28 years under normal operating conditions.\"\"\",\n",
        "]\n",
        "\n",
        "count = index_builder.index_industrial_texts(sample_industrial, source=\"demo_manual\")\n",
        "print(f\"âœ… Indexed {count} industrial chunks\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Recipe Domain â”€â”€\n",
        "# Option A: Load from Food.com CSV\n",
        "# index_builder.index_recipes('./data/RAW_recipes.csv', max_rows=50000)\n",
        "\n",
        "# Option B: Sample data for demo\n",
        "from ingestion.document_loader import DocumentLoader\n",
        "from ingestion.chunking_pipeline import ChunkingPipeline\n",
        "\n",
        "sample_recipes = [\n",
        "    \"\"\"Recipe: Classic Chocolate Chip Cookies\n",
        "    Prep Time: 45 minutes\n",
        "    Ingredients: 2 1/4 cups flour, 1 tsp baking soda, 1 tsp salt,\n",
        "    1 cup butter softened, 3/4 cup sugar, 3/4 cup brown sugar,\n",
        "    2 large eggs, 2 tsp vanilla, 2 cups chocolate chips\n",
        "    Steps: 1. Preheat oven to 375F. 2. Mix dry ingredients.\n",
        "    3. Cream butter and sugars. 4. Beat in eggs and vanilla.\n",
        "    5. Gradually blend in flour mixture. 6. Stir in chips.\n",
        "    7. Drop rounded tablespoons onto baking sheets.\n",
        "    8. Bake 9 to 11 minutes until golden brown.\n",
        "    Egg Substitutes: For egg-free version, use 1/4 cup unsweetened\n",
        "    applesauce per egg or 1 mashed banana per egg.\"\"\",\n",
        "\n",
        "    \"\"\"Recipe: Quick Chicken Stir-Fry\n",
        "    Prep Time: 20 minutes\n",
        "    Ingredients: 1 lb chicken breast, 2 bell peppers, 1 cup rice,\n",
        "    3 tbsp soy sauce, 1 tbsp sesame oil, 2 cloves garlic, ginger\n",
        "    Steps: 1. Cook rice according to package directions.\n",
        "    2. Slice chicken into strips. 3. Heat oil in wok over high heat.\n",
        "    4. Stir-fry chicken 5-6 minutes. 5. Add vegetables and garlic.\n",
        "    6. Add soy sauce and ginger. 7. Serve over rice.\n",
        "    Nutrition: ~450 calories per serving, 35g protein.\"\"\",\n",
        "]\n",
        "\n",
        "recipe_docs = DocumentLoader.from_texts(sample_recipes, \"recipe\", \"demo_recipes\")\n",
        "chunker = ChunkingPipeline()\n",
        "recipe_chunks = chunker.chunk_documents(recipe_docs, domain=\"recipe\")\n",
        "count = vector_store.add_documents(\"recipe\", recipe_chunks)\n",
        "print(f\"âœ… Indexed {count} recipe chunks\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Scientific Domain â”€â”€\n",
        "# ArXiv papers are fetched on-demand by the scientific agent,\n",
        "# but we can pre-index some for faster demos\n",
        "try:\n",
        "    count = index_builder.index_arxiv_papers(\n",
        "        \"transformer attention mechanism\", max_results=5\n",
        "    )\n",
        "    print(f\"âœ… Indexed {count} scientific chunks\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ ArXiv fetch failed (network issue?): {e}\")\n",
        "    print(\"Scientific agent will try on-demand fetching at query time\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check indexing status\n",
        "print(\"\\nðŸ“Š Index Status:\")\n",
        "for stat in vector_store.get_all_stats():\n",
        "    print(f\"  {stat['domain']:>12}: {stat['document_count']} chunks\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build & Run the Workflow"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from orchestration.workflow_graph import build_workflow, run_query\n",
        "\n",
        "# Build the complete LangGraph workflow\n",
        "workflow = build_workflow(\n",
        "    llm=llm,\n",
        "    vector_store=vector_store,\n",
        "    index_builder=index_builder,\n",
        ")\n",
        "print(\"âœ… Workflow compiled\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Test: Industrial Query â”€â”€\n",
        "result = run_query(workflow, \"My S7-1200 PLC is showing fault code F0003\")\n",
        "print(f\"Domain: {result['domain']}\")\n",
        "print(f\"Confidence: {result['confidence']:.2f}\")\n",
        "print(f\"\\nResponse:\\n{result['response']}\")\n",
        "print(f\"\\nSources: {result['sources']}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Test: Recipe Query â”€â”€\n",
        "result = run_query(workflow, \"What can I substitute for eggs in cookies?\")\n",
        "print(f\"Domain: {result['domain']}\")\n",
        "print(f\"Confidence: {result['confidence']:.2f}\")\n",
        "print(f\"\\nResponse:\\n{result['response']}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Test: Scientific Query â”€â”€\n",
        "result = run_query(workflow, \"Summarize recent papers on transformer attention\")\n",
        "print(f\"Domain: {result['domain']}\")\n",
        "print(f\"Confidence: {result['confidence']:.2f}\")\n",
        "print(f\"\\nResponse:\\n{result['response']}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Test: Ambiguous Query (should trigger clarification) â”€â”€\n",
        "result = run_query(\n",
        "    workflow,\n",
        "    \"What temperature should I cook chicken to avoid equipment failure?\"\n",
        ")\n",
        "print(f\"Domain: {result['domain']}\")\n",
        "print(f\"Needs clarification: {result['needs_clarification']}\")\n",
        "print(f\"\\nResponse:\\n{result['response']}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Evaluation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluation.metrics import Evaluator, INDUSTRIAL_TEST_QUERIES\n",
        "\n",
        "evaluator = Evaluator(workflow=workflow, llm=llm)\n",
        "\n",
        "# Run routing evaluation on a subset\n",
        "routing_results = evaluator.evaluate_routing(\n",
        "    test_queries=INDUSTRIAL_TEST_QUERIES[:5]  # Quick test with 5 queries\n",
        ")\n",
        "\n",
        "print(f\"Routing Accuracy: {routing_results['overall_accuracy']:.2%}\")\n",
        "print(f\"Per-Domain: {routing_results['per_domain_accuracy']}\")\n",
        "print(f\"\\nDetailed Results:\")\n",
        "for r in routing_results['results']:\n",
        "    status = 'âœ…' if r['correct'] else 'âŒ'\n",
        "    print(f\"  {status} [{r['actual']:>12}] {r['query'][:60]}...\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM-Judge quality assessment\n",
        "sample_result = run_query(workflow, \"How to reset a PowerFlex 525 drive?\")\n",
        "judge_score = evaluator.evaluate_llm_judge(\n",
        "    query=\"How to reset a PowerFlex 525 drive?\",\n",
        "    response=sample_result['response'],\n",
        "    domain=sample_result['domain'],\n",
        ")\n",
        "print(\"LLM-Judge Scores:\")\n",
        "for k, v in judge_score.items():\n",
        "    print(f\"  {k}: {v}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Interactive Demo"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive query loop\n",
        "print(\"ðŸ¤– Multi-Domain Assistant Ready!\")\n",
        "print(\"Domains: Industrial | Recipe | Scientific\")\n",
        "print(\"Type 'quit' to exit\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"You: \")\n",
        "    if query.lower() in ('quit', 'exit', 'q'):\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    result = run_query(workflow, query)\n",
        "    print(f\"\\n[Routed to: {result['domain']} | Confidence: {result['confidence']:.2f}]\")\n",
        "    print(f\"Assistant: {result['response']}\\n\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
