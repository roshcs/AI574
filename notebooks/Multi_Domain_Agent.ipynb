{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AI574'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 68 (delta 16), reused 66 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (68/68), 180.78 KiB | 278.00 KiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/content/AI574\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('/content/AI574'):\n",
        "    !git clone https://github.com/roshcs/AI574.git\n",
        "%cd /content/AI574\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chU4cUFvmDUb",
        "outputId": "09dfbed7-f62a-49b7-d6fa-e24a53f4b519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "Memory: 85.1 GB\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Project directory: /content/drive/MyDrive/AI574_Multi_Domain_Agent\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Create a persistent project directory\n",
        "import os\n",
        "PROJECT_DIR = '/content/drive/MyDrive/AI574_Multi_Domain_Agent'\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{PROJECT_DIR}/data', exist_ok=True)\n",
        "os.makedirs(f'{PROJECT_DIR}/models', exist_ok=True)\n",
        "print(f'Project directory: {PROJECT_DIR}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kH_erhJWpVc8"
      },
      "outputs": [],
      "source": [
        "# Action: Run this cell to install all packages:\n",
        "\n",
        "# %%capture\n",
        "!pip install -q \\\n",
        "  \"langchain>=0.3.0\" \"langchain-core>=0.3.0\" \"langgraph>=0.2.0\" \"langchain-text-splitters>=0.2.0\" \\\n",
        "  \"keras>=3.0\" \"keras-hub>=0.17.0\" \\\n",
        "  \"sentence-transformers>=3.0.0\" \"transformers>=4.45,<5.0\" \"chromadb>=0.5.0\" \\\n",
        "  \"PyPDF2>=3.0.0\" \"arxiv>=2.1.0\" \"pydantic>=2.0\"\n",
        "\n",
        "!pip install -q \"jax[cuda12]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTt0KS_jqRiY",
        "outputId": "f7c352a5-98b9-4278-acd1-33583fd75aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras backend: jax\n",
            "Keras version: 3.10.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'jax'\n",
        "\n",
        "# Verify\n",
        "import keras\n",
        "print(f'Keras backend: {keras.backend.backend()}')\n",
        "print(f'Keras version: {keras.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPPKReZZquJR",
        "outputId": "793591bd-a513-4f9b-faa1-c402e002b1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n",
            "JAX devices: [CudaDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "import langgraph\n",
        "import keras_hub\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import jax\n",
        "print('All imports successful!')\n",
        "print(f'JAX devices: {jax.devices()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhvPnZR8q8JX",
        "outputId": "799e0336-8a16-421f-fb91-44cf75bfff8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project structure created at: /content/drive/MyDrive/AI574_Multi_Domain_Agent/project\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# PROJECT_DIR is already defined\n",
        "PROJECT_ROOT = os.path.join(PROJECT_DIR, 'project')\n",
        "\n",
        "dirs = [\n",
        "    'config',\n",
        "    'foundation',\n",
        "    'ingestion',\n",
        "    'rag_core',\n",
        "    'agents',\n",
        "    'orchestration',\n",
        "    'evaluation',\n",
        "    'data/industrial',\n",
        "    'data/recipes',\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "for d in dirs:\n",
        "    os.makedirs(os.path.join(PROJECT_ROOT, d), exist_ok=True)\n",
        "\n",
        "# Create __init__.py in every package directory\n",
        "packages = [\n",
        "    'config',\n",
        "    'foundation',\n",
        "    'ingestion',\n",
        "    'rag_core',\n",
        "    'agents',\n",
        "    'orchestration',\n",
        "    'evaluation'\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    init_file = os.path.join(PROJECT_ROOT, pkg, '__init__.py')\n",
        "    open(init_file, 'a').close()\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "print('Project structure created at:', PROJECT_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC74O-8l39hm",
        "outputId": "f636bce9-3ff5-469f-a7d8-af577f9ed92e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT = /content/drive/MyDrive/AI574_Multi_Domain_Agent/project\n",
            "foundation exists? True\n",
            "init exists? True\n",
            "files: ['embedding_service.py', 'vector_store.py', '__init__.py', '__pycache__', 'llm_wrapper.py']\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "# PROJECT_DIR already defined elsewhere\n",
        "PROJECT_ROOT = os.path.join(PROJECT_DIR, \"project\")\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
        "print(\"foundation exists?\", os.path.isdir(os.path.join(PROJECT_ROOT, \"foundation\")))\n",
        "print(\"init exists?\", os.path.isfile(os.path.join(PROJECT_ROOT, \"foundation\", \"__init__.py\")))\n",
        "print(\"files:\", os.listdir(os.path.join(PROJECT_ROOT, \"foundation\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHco0kHFxK_4",
        "outputId": "803dbd8b-6d0f-49c8-f6e2-6b8913200e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM: gemma3_instruct_12b\n",
            "Embeddings: thenlper/gte-large\n",
            "Domains: ['industrial', 'recipe', 'scientific']\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from config.settings import CONFIG, LLMConfig\n",
        "from foundation.llm_wrapper import KerasHubChatModel\n",
        "from foundation.embedding_service import EmbeddingService\n",
        "from foundation.vector_store import VectorStoreService\n",
        "\n",
        "# Print configuration\n",
        "print(f\"LLM: {CONFIG.llm.preset}\")\n",
        "print(f\"Embeddings: {CONFIG.embedding.model_name}\")\n",
        "print(f\"Domains: {CONFIG.supervisor.domains}\")\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"roshcs\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"781502c08d14d778d3d23d4e58ca0751\"\n",
        "\n",
        "# os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "# os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFv6CWdjZr3p",
        "outputId": "0b918478-a54e-482f-907f-c421e42bc1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LLM loaded\n"
          ]
        }
      ],
      "source": [
        "# Now try loading\n",
        "from foundation.llm_wrapper import KerasHubChatModel\n",
        "from config.settings import CONFIG\n",
        "\n",
        "llm = KerasHubChatModel(config=CONFIG.llm)\n",
        "print(\"✅ LLM loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346,
          "referenced_widgets": [
            "ea261468f2fb4e298e05bb849149ad9e",
            "9ab1fc07ce6742538a7081af05d0fd10",
            "354972c523ce4d25ae0b07045e6de40f",
            "68be00db64404c2e8a95f17102aa5f37",
            "93599041a32242bbb2527fc0a4b56c60",
            "d39eb82fa9de4a10af9aab0dadf236e0",
            "ad1ae9efd35a41d2bfabf40ad76d0766",
            "299165972c294cc68c7a8c307769ffd3",
            "bcd2d27bc236417194238612637ddeed",
            "d46f8e82073e459bbfbf80f6163c924b",
            "6fb0aaf970ba402db62d242c5b098c9e"
          ]
        },
        "id": "FAg2AkLMaEo9",
        "outputId": "5bf9e230-2832-46e3-86aa-7f392c9ecbd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:foundation.embedding_service:Failed to load embedding model: Can't load the configuration of 'BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dtype\": \"float16\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.6\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"dtype\": \"float16\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.6\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "' is the correct path to a directory containing a config.json file\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Can't load the configuration of 'BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float16\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.57.6\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float16\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.57.6\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n' is the correct path to a directory containing a config.json file",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREPO_ID_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34m\"Repo id must use alphanumeric chars, '-', '_' or '.'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: 'BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float16\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.57.6\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         resolved_files = [\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     resolved_file = try_to_load_from_cache(\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREPO_ID_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34m\"Repo id must use alphanumeric chars, '-', '_' or '.'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: 'BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float16\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.57.6\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-244218321.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfoundation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbeddingService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddingService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PLC fault code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/AI574_Multi_Domain_Agent/project/foundation/embedding_service.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/AI574_Multi_Domain_Agent/project/foundation/embedding_service.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading embedding model: {model_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             self._model = SentenceTransformer(\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             ):\n\u001b[0;32m--> 327\u001b[0;31m                 modules, self.module_kwargs = self._load_sbert_model(\n\u001b[0m\u001b[1;32m    328\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   2303\u001b[0m                 \u001b[0;31m# Newer modules that support the new loading method are loaded with the new style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m                 \u001b[0;31m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m                 module = module_class.load(\n\u001b[0m\u001b[1;32m   2306\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m                     \u001b[0;31m# Loading-specific keyword arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         )\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Get the signature of the auto_model's forward method to pass only the expected arguments from `features`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_mt5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 self.auto_model = AutoModel.from_pretrained(\n\u001b[0m\u001b[1;32m    198\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4842\u001b[0m             \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4843\u001b[0;31m             config, model_kwargs = cls.config_class.from_pretrained(\n\u001b[0m\u001b[1;32m   4844\u001b[0m                 \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4845\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_token_in_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_config_key\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_config_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_config_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 raise OSError(\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;34mf\"Can't load the configuration of '{pretrained_model_name_or_path}'. If you were trying to load it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0;34m\" from 'https://huggingface.co/models', make sure you don't have a local directory with the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float16\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.57.6\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"dtype\": \"float16\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.57.6\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n' is the correct path to a directory containing a config.json file"
          ]
        }
      ],
      "source": [
        "from foundation.embedding_service import EmbeddingService\n",
        "\n",
        "embedder = EmbeddingService()\n",
        "\n",
        "test_vec = embedder.embed_query(\"PLC fault code\")\n",
        "print(f\"✅ Embedding dimension: {len(test_vec)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf66QNfkgpau",
        "outputId": "b02f0805-0d8c-443d-c75d-83eab2f0dd8e"
      },
      "outputs": [],
      "source": [
        "from foundation.vector_store import VectorStoreService\n",
        "\n",
        "vs = VectorStoreService(embedding_service=embedder)\n",
        "print(\"✅ Vector store initialized\")\n",
        "print(vs.get_all_stats())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6UJ9FGhKqk",
        "outputId": "42e46ac2-0a18-454b-aca4-4ca250a92853"
      },
      "outputs": [],
      "source": [
        "from ingestion.index_builder import IndexBuilder\n",
        "from ingestion.document_loader import DocumentLoader\n",
        "from ingestion.chunking_pipeline import ChunkingPipeline\n",
        "\n",
        "builder = IndexBuilder(vector_store=vs)\n",
        "\n",
        "# ── Industrial: Rockwell Automation / Allen-Bradley ──\n",
        "sample_industrial = [\n",
        "    \"\"\"Fault Code F002 - Allen-Bradley PowerFlex 525 VFD: Auxiliary Input.\n",
        "    Description: An external fault has been detected via the auxiliary input terminal.\n",
        "    Possible Causes:\n",
        "    1. External device connected to auxiliary input is reporting a fault condition\n",
        "    2. Wiring issue on the auxiliary digital input terminal\n",
        "    3. Incorrect parameter configuration for the auxiliary input function\n",
        "    Troubleshooting Steps:\n",
        "    1. Check the external device connected to the auxiliary input for faults\n",
        "    2. Verify wiring connections on terminal block TB2\n",
        "    3. Check parameter A070 [Fault Config 2] for correct auxiliary input configuration\n",
        "    4. Inspect for damaged or loose wiring on the digital input terminals\n",
        "    Resolution: Clear the external fault condition and reset the drive by cycling the Enable input or pressing the Stop/Reset key on the HIM.\"\"\",\n",
        "\n",
        "    \"\"\"Fault Code F004 - Allen-Bradley PowerFlex 525 VFD: Undervoltage.\n",
        "    Description: The DC bus voltage has dropped below the undervoltage trip level.\n",
        "    Possible Causes:\n",
        "    1. Input power supply voltage too low or momentary power dip\n",
        "    2. Incoming power supply fuses blown or circuit breaker tripped\n",
        "    3. Loose connections on input power terminals R/L1, S/L2, T/L3\n",
        "    4. DC bus capacitors degraded (check capacitor health indicator LED)\n",
        "    Troubleshooting Steps:\n",
        "    1. Measure incoming line voltage at drive terminals - must be within nameplate rating +/-10%\n",
        "    2. Check all three phases for voltage balance (max 3% imbalance)\n",
        "    3. Inspect and tighten input power terminal connections (torque to 1.4 Nm)\n",
        "    4. Check parameter A531 [DC Bus Voltage] for current reading\n",
        "    5. Review fault log in parameter A700-A706 for fault history and timestamps\n",
        "    Resolution: Restore proper input voltage. If capacitors are degraded, replace the drive.\n",
        "    SAFETY: Disconnect and lockout/tagout all power sources before inspecting terminals.\n",
        "    Wait 5 minutes for DC bus capacitors to discharge before servicing.\"\"\",\n",
        "\n",
        "    \"\"\"Fault Code F005 - Allen-Bradley PowerFlex 525 VFD: Overvoltage.\n",
        "    Description: The DC bus voltage has exceeded the overvoltage trip level.\n",
        "    Possible Causes:\n",
        "    1. Input line voltage exceeds drive nameplate rating\n",
        "    2. Excessive regenerative energy from motor deceleration (overhauling load)\n",
        "    3. Deceleration time too short for the load inertia\n",
        "    4. Dynamic brake resistor circuit failure or incorrect sizing\n",
        "    Troubleshooting Steps:\n",
        "    1. Measure input voltage - must not exceed 528 VAC for 480V class drives\n",
        "    2. Increase deceleration time in parameter A092 [Decel Time 1]\n",
        "    3. Enable bus regulator: set parameter A540 [Bus Reg Mode] to option 1 (Enabled)\n",
        "    4. If using dynamic braking, check DB resistor connections and resistance value\n",
        "    5. Check parameter A531 [DC Bus Voltage] - nominal is ~650V for 480V input\n",
        "    Resolution: Reduce input voltage or extend deceleration time. Add DB resistor for overhauling loads.\"\"\",\n",
        "\n",
        "    \"\"\"Allen-Bradley CompactLogix 5380 Controller - EtherNet/IP Configuration Guide.\n",
        "    Model: 1769-L33ER CompactLogix 5380\n",
        "    Prerequisites: RSLogix 5000 v32+ or Studio 5000 Logix Designer v32+\n",
        "    Step 1: Create new project - select 1769-L33ER controller, revision 32+\n",
        "    Step 2: Configure controller IP address via USB connection using BOOTP/DHCP tool\n",
        "    Step 3: Add EtherNet/IP module in I/O Configuration tree\n",
        "    Step 4: Right-click controller > Properties > set IP address (e.g., 192.168.1.10)\n",
        "    Step 5: Add remote I/O devices - right-click EtherNet/IP > New Module\n",
        "    Step 6: Configure Produced/Consumed tags for controller-to-controller communication\n",
        "    Step 7: Download program and verify connection indicators:\n",
        "      - OK LED: Solid green = running, Flashing green = program mode\n",
        "      - ENET LED: Solid green = has connections, Flashing green = no connections\n",
        "    Common Issue: If ENET LED is off, check IP config and network switch connection.\n",
        "    Use RSLinx Classic > RSWho to verify controller appears on EtherNet/IP network.\"\"\",\n",
        "\n",
        "    \"\"\"Allen-Bradley PanelView Plus 7 HMI - Troubleshooting Communication Failures.\n",
        "    Symptom: PanelView displays \"Controller not found\" or shows stale data.\n",
        "    Possible Causes:\n",
        "    1. Incorrect IP address or subnet mask configuration\n",
        "    2. EtherNet/IP cable disconnected or faulty\n",
        "    3. RSLinx Enterprise communication path misconfigured\n",
        "    4. Controller is in Program mode instead of Run mode\n",
        "    Troubleshooting Steps:\n",
        "    1. On PanelView: press Terminal Settings > Networks > verify IP address\n",
        "    2. Ping the controller IP from PanelView diagnostics screen\n",
        "    3. In FactoryTalk View Studio: check Communication Setup > verify shortcut path\n",
        "    4. Ensure controller and HMI are on same subnet (e.g., both 192.168.1.x/24)\n",
        "    5. Check Ethernet cable and switch port LEDs for link activity\n",
        "    6. Review controller mode - must be in Run or Remote Run for live data\n",
        "    Resolution: Correct IP addressing and verify physical network connectivity.\n",
        "    If using managed switch, verify VLANs are not isolating devices.\"\"\",\n",
        "\n",
        "    \"\"\"Preventive Maintenance Schedule - Allen-Bradley PowerFlex 755 Drive System.\n",
        "    Weekly: Check drive status LEDs and HIM display for active alarms\n",
        "    Monthly: Inspect cooling fans for proper operation, clean air filters\n",
        "    Quarterly: Verify DC bus voltage (parameter 15 - Bus Voltage), check capacitor\n",
        "    formation indicator, tighten all power and control terminal connections\n",
        "    Semi-Annually: Thermal scan of power connections, verify ground fault monitoring,\n",
        "    backup drive parameters using Connected Components Workbench (CCW)\n",
        "    Annually: Full parameter backup, firmware version audit against Rockwell\n",
        "    compatibility matrix, capacitor health test, clean power module heat sinks\n",
        "    Every 5 Years: Replace cooling fans (recommended life), capacitor reformation\n",
        "    MTBF: PowerFlex 755 rated at approximately 200,000 hours (28+ years) at 40C ambient.\n",
        "    Critical Spares to Stock: Cooling fan assembly (KIT-F755FAN), control board fuse,\n",
        "    fiber optic cables for multi-axis configurations.\"\"\",\n",
        "]\n",
        "\n",
        "count = builder.index_industrial_texts(sample_industrial, source=\"rockwell_automation\")\n",
        "print(f\"✅ Indexed {count} industrial chunks\")\n",
        "\n",
        "# ── Recipe sample data ──\n",
        "sample_recipes = [\n",
        "    \"\"\"Recipe: Classic Chocolate Chip Cookies\n",
        "    Prep Time: 45 minutes. Ingredients: 2 1/4 cups flour, 1 tsp baking soda,\n",
        "    1 tsp salt, 1 cup butter softened, 3/4 cup sugar, 3/4 cup brown sugar,\n",
        "    2 large eggs, 2 tsp vanilla, 2 cups chocolate chips.\n",
        "    Egg Substitutes: Use 1/4 cup unsweetened applesauce per egg,\n",
        "    or 1 mashed banana per egg, or 3 tbsp aquafaba per egg.\"\"\",\n",
        "\n",
        "    \"\"\"Recipe: Quick Chicken Stir-Fry\n",
        "    Prep Time: 20 minutes. Ingredients: 1 lb chicken breast, 2 bell peppers,\n",
        "    1 cup rice, 3 tbsp soy sauce, 1 tbsp sesame oil, 2 cloves garlic, ginger.\n",
        "    Steps: Cook rice. Slice chicken. Heat oil in wok over high heat.\n",
        "    Stir-fry chicken 5-6 min. Add vegetables and garlic. Add soy sauce.\n",
        "    Nutrition: ~450 calories per serving, 35g protein.\"\"\",\n",
        "\n",
        "    \"\"\"Recipe: Homemade Margherita Pizza\n",
        "    Prep Time: 90 minutes (including dough rise). Ingredients: 3 cups flour,\n",
        "    1 packet yeast, 1 cup warm water, 2 tbsp olive oil, 1 tsp salt, 1 tsp sugar,\n",
        "    1 cup crushed San Marzano tomatoes, 8 oz fresh mozzarella, fresh basil.\n",
        "    Steps: Mix dough, let rise 1 hour. Preheat oven to 475F. Stretch dough,\n",
        "    add sauce and cheese. Bake 12-15 min until crust is golden.\n",
        "    Gluten-Free Alternative: Substitute 3 cups gluten-free flour blend plus\n",
        "    1 tsp xanthan gum for regular flour.\"\"\",\n",
        "]\n",
        "\n",
        "recipe_docs = DocumentLoader.from_texts(sample_recipes, \"recipe\", \"demo_recipes\")\n",
        "chunker = ChunkingPipeline()\n",
        "recipe_chunks = chunker.chunk_documents(recipe_docs, domain=\"recipe\")\n",
        "count = vs.add_documents(\"recipe\", recipe_chunks)\n",
        "print(f\"✅ Indexed {count} recipe chunks\")\n",
        "\n",
        "# ── Scientific sample data ──\n",
        "sample_scientific = [\n",
        "    \"\"\"Title: Attention Is All You Need\n",
        "    Authors: Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, Polosukhin\n",
        "    Abstract: We propose a new network architecture, the Transformer, based solely\n",
        "    on attention mechanisms, dispensing with recurrence and convolutions entirely.\n",
        "    The Transformer allows for significantly more parallelization and achieves\n",
        "    new state of the art in translation quality. ArXiv ID: 1706.03762\"\"\",\n",
        "\n",
        "    \"\"\"Title: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
        "    Authors: Lewis, Perez, Piktus, Petroni, Karpukhin, Goyal, Kuttler, Lewis, Yih, Rocktaschel, Riedel, Kiela\n",
        "    Abstract: We explore a general-purpose fine-tuning recipe for retrieval-augmented\n",
        "    generation (RAG) which combines pre-trained parametric and non-parametric memory\n",
        "    for language generation. ArXiv ID: 2005.11401\"\"\",\n",
        "\n",
        "    \"\"\"Title: Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection\n",
        "    Authors: Asai, Wu, Wang, Sil, Hajishirzi\n",
        "    Abstract: We introduce Self-RAG, a framework that trains a single LM to adaptively\n",
        "    retrieve passages on demand, generate text informed by retrieved passages, and\n",
        "    critique its own output using special reflection tokens. Self-RAG significantly\n",
        "    outperforms existing RAG approaches and LLMs on multiple tasks. ArXiv ID: 2310.11511\"\"\",\n",
        "]\n",
        "\n",
        "sci_docs = DocumentLoader.from_texts(sample_scientific, \"scientific\", \"demo_papers\")\n",
        "sci_chunks = chunker.chunk_documents(sci_docs, domain=\"scientific\")\n",
        "count = vs.add_documents(\"scientific\", sci_chunks)\n",
        "print(f\"✅ Indexed {count} scientific chunks\")\n",
        "\n",
        "# Status check\n",
        "print(\"\\n📊 Index Status:\")\n",
        "for stat in vs.get_all_stats():\n",
        "    print(f\"  {stat['domain']:>12}: {stat['document_count']} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DQiyqf5msKV",
        "outputId": "241033b8-5c83-41ee-fc34-cd133387b4e8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Make sure the project root is at the FRONT of the path\n",
        "PROJECT = '/content/drive/MyDrive/AI574_Multi_Domain_Agent/project'\n",
        "if PROJECT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT)\n",
        "\n",
        "# Verify the right modules are found\n",
        "import agents.industrial_agent\n",
        "print(f\"✅ Found: {agents.industrial_agent.__file__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CHfDt8Eke6y",
        "outputId": "ca247829-a925-460f-9ed2-2ad0ebca6453"
      },
      "outputs": [],
      "source": [
        "import importlib, orchestration.workflow_graph, orchestration.state_schema\n",
        "importlib.reload(orchestration.state_schema)\n",
        "importlib.reload(orchestration.workflow_graph)\n",
        "from orchestration.workflow_graph import build_workflow, run_query\n",
        "\n",
        "try:\n",
        "    llm, vs, builder\n",
        "except NameError:\n",
        "    raise RuntimeError(\n",
        "        \"Run the cells above first so 'llm', 'vs', and 'builder' exist: \"\n",
        "        \"load LLM, create embedder & vector store, run IndexBuilder and index data.\"\n",
        "    )\n",
        "\n",
        "workflow = build_workflow(llm=llm, vector_store=vs, index_builder=builder)\n",
        "print(\"✅ Workflow compiled!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_result(result):\n",
        "    \"\"\"Pretty-print query result with visual timing breakdown.\"\"\"\n",
        "    domain = result.get(\"domain\", \"?\")\n",
        "    conf   = result.get(\"confidence\", 0)\n",
        "    status = result.get(\"status\", \"?\")\n",
        "    esc    = result.get(\"escalated\", False)\n",
        "    srcs   = result.get(\"sources\", [])\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  Domain: {domain:<14} Confidence: {conf:.2f}\")\n",
        "    print(f\"  Status: {status:<14} Escalated:  {esc}\")\n",
        "    print(f\"  Sources: {len(srcs)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\n{result.get('response', '')}\")\n",
        "\n",
        "    # ── Timing ──────────────────────────────────────────────────\n",
        "    t = result.get(\"timing\")\n",
        "    if not t:\n",
        "        print(\"\\n  (no timing data — run sync cell to update workflow_graph.py)\")\n",
        "        return\n",
        "\n",
        "    total = t.get(\"total_s\", 0) or 0.001\n",
        "    sup   = t.get(\"supervisor_s\", 0)\n",
        "    agent = t.get(\"agent_s\", 0)\n",
        "    c     = t.get(\"crag\") or {}\n",
        "\n",
        "    retrieve = c.get(\"retrieve_s\", 0)\n",
        "    grade    = c.get(\"grade_s\", 0)\n",
        "    rewrite  = c.get(\"rewrite_s\", 0)\n",
        "    generate = c.get(\"generate_s\", 0)\n",
        "    validate = c.get(\"validate_s\", 0)\n",
        "    overhead = max(0, agent - (retrieve + grade + rewrite + generate + validate))\n",
        "\n",
        "    steps = [\n",
        "        (\"Supervisor\", sup),\n",
        "        (\"  Retrieve\", retrieve),\n",
        "        (\"  Grade\",    grade),\n",
        "        (\"  Rewrite\",  rewrite),\n",
        "        (\"  Generate\", generate),\n",
        "        (\"  Validate\", validate),\n",
        "        (\"  Overhead\", overhead),\n",
        "    ]\n",
        "\n",
        "    BAR = 25\n",
        "    print(f\"\\n{'─'*60}\")\n",
        "    print(f\"  TIMING BREAKDOWN  (total {total:.1f}s / {total/60:.2f} min)\")\n",
        "    print(f\"{'─'*60}\")\n",
        "    for label, s in steps:\n",
        "        if s < 0.01 and label == \"  Rewrite\":\n",
        "            continue\n",
        "        pct  = (s / total) * 100\n",
        "        fill = int(BAR * s / total)\n",
        "        bar  = \"█\" * fill + \"░\" * (BAR - fill)\n",
        "        print(f\"  {label:<12} {bar} {s:5.1f}s  ({pct:4.1f}%)\")\n",
        "    print(f\"{'─'*60}\")\n",
        "    print(f\"  {'Total':<12} {'':>{BAR}} {total:5.1f}s\")\n",
        "    print(f\"{'─'*60}\")\n",
        "\n",
        "# ── Run test query ──────────────────────────────────────────────────────────\n",
        "result = run_query(workflow, \"My PowerFlex 525 drive is showing fault F004, how do I fix it?\")\n",
        "display_result(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rrmjqQeqKww",
        "outputId": "6003ac82-629e-463e-f6de-7cdada89bd55"
      },
      "outputs": [],
      "source": [
        "# Test: Recipe query\n",
        "result = run_query(workflow, \"What can I substitute for eggs in cookies?\")\n",
        "display_result(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg5BM0HpsuDR",
        "outputId": "20661136-a666-4a26-e80f-ec99a9137b83"
      },
      "outputs": [],
      "source": [
        "# Test: Scientific query\n",
        "result = run_query(workflow, \"Summarize the key ideas behind RAG in NLP\")\n",
        "display_result(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w8knd59svrw",
        "outputId": "09fb5722-193c-4ae2-b546-be72cadd07df"
      },
      "outputs": [],
      "source": [
        "# Test: Ambiguous query (should trigger clarification)\n",
        "result = run_query(workflow, \"What temperature should I set to avoid failure?\")\n",
        "display_result(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why does one query take 3+ minutes? / LLM throughput on A100\n",
        "\n",
        "**Reasons:**\n",
        "1. **Multiple LLM calls per query** — Supervisor (route) + batch grader + response generator + hallucination check = **4 sequential calls**. Each call is a full 9B forward/generation.\n",
        "2. **Keras/JAX is not an inference-optimized stack** — Frameworks like TensorRT-LLM or vLLM get **~50–60 tok/s** for 8–10B on A100. Keras Hub on JAX typically does **~5–20 tok/s** (no fused kernels, no continuous batching).\n",
        "3. **Rough token budget per query** — ~80 (supervisor) + ~300 (grader) + ~400–800 (generator) + ~80 (hallucination) ≈ **900–1300 output tokens**. At 10 tok/s that’s 90–130 s just for generation; add overhead and you get 3+ min.\n",
        "\n",
        "**To see your actual throughput:** run the cell below and check the log lines `LLM call: Xs | ~Y output tokens | ~Z tok/s`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable INFO logging so \"LLM call: ... tok/s\" lines appear\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
        "for _ in [\"foundation.llm_wrapper\", \"rag_core.crag_pipeline\"]:\n",
        "    logging.getLogger(_).setLevel(logging.INFO)\n",
        "\n",
        "# Timed re-run with full breakdown\n",
        "result = run_query(workflow, \"My PowerFlex 525 drive is showing fault F004, how do I fix it?\")\n",
        "display_result(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSK54iS27IDT"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "299165972c294cc68c7a8c307769ffd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354972c523ce4d25ae0b07045e6de40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299165972c294cc68c7a8c307769ffd3",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcd2d27bc236417194238612637ddeed",
            "value": 391
          }
        },
        "68be00db64404c2e8a95f17102aa5f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d46f8e82073e459bbfbf80f6163c924b",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb0aaf970ba402db62d242c5b098c9e",
            "value": " 391/391 [00:00&lt;00:00, 1357.94it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "6fb0aaf970ba402db62d242c5b098c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93599041a32242bbb2527fc0a4b56c60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab1fc07ce6742538a7081af05d0fd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d39eb82fa9de4a10af9aab0dadf236e0",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1ae9efd35a41d2bfabf40ad76d0766",
            "value": "Loading weights: 100%"
          }
        },
        "ad1ae9efd35a41d2bfabf40ad76d0766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcd2d27bc236417194238612637ddeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d39eb82fa9de4a10af9aab0dadf236e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46f8e82073e459bbfbf80f6163c924b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea261468f2fb4e298e05bb849149ad9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ab1fc07ce6742538a7081af05d0fd10",
              "IPY_MODEL_354972c523ce4d25ae0b07045e6de40f",
              "IPY_MODEL_68be00db64404c2e8a95f17102aa5f37"
            ],
            "layout": "IPY_MODEL_93599041a32242bbb2527fc0a4b56c60"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
